# pip install scikit-learn

# -*- coding: utf-8 -*-
"""LAB 7 - Spam Detection Deploy

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19gP0ho4NDaa5-MtF_esyJRW2-F6hHK7F
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

# READING THE CSV FILE:
DF = pd.read_csv("/content/drive/MyDrive/Lab/ML/Lab - 5/spam.csv", encoding = "ISO-8859-1")

# Columns
C = ["class", "text"]

DF = DF[DF.columns[:2]]
DF.columns = C

# Class - 1 FOR SPAM
# Class - 0 FOR NOT SPAM
DF["class"] = (DF["class"] == "ham").astype("int")

"""# **STOP WORD REMOVAL**"""

import nltk # NATURAL LANGUAGE TOOLKIT
nltk.download('stopwords')
from nltk.corpus import stopwords
import string

punctuations = [i for i in string.punctuation]
stop_words = set((stopwords.words("english") + punctuations))

from nltk.tokenize import word_tokenize, sent_tokenize

nltk.download("punkt")

# Tokenize & Stop Word Removal:
DF["text"]
N = DF.shape[0]

for i in range(N):
  word_tokens = word_tokenize(DF["text"][i])

  # Converts the words in word_tokens to lower case and then checks whether they are present in stop_words or not:

  filtered = ""
    
  for w in word_tokens:
      if w.lower() not in stop_words:
          filtered += w 
          filtered += " "

  # print(filtered)
  DF["text"][i] = filtered

"""# **COUNT VECTORIZER:**"""
import sklearn
from sklearn.feature_extraction.text import CountVectorizer

CV = CountVectorizer()
X = CV.fit_transform(DF["text"])
Y = DF["class"]

"""**TEST - TRAIN SPLIT:**"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.20, random_state=42)

"""**TRAINING MODEL:**"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

LR = LogisticRegression()
LR.fit(x_train, y_train)

"""**Checking The Accuracy:**"""

y_predict = LR.predict(x_test)
print(classification_report(y_test, y_predict))

"""# **PICKLE:**"""

import pickle

pickle.dump(LR, open("SpamModel.pkl", "wb"))